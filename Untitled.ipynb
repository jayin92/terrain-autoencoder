{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\nimport torch, torchvision\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport random\\nimport util\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\nimport torch, torchvision\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport random\\nimport util\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "import torch, torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"class empty:\\n    pass\\n\\n\\nc = empty()\\nc.name = \\\"t0811\\\"\\nc.inputNC = 1\\nc.outputNC = 1\\nc.depth = 4\\nc.structEncNC = np.array([1, 2, 4, 8]) * 64\\nc.structEncOutNC = c.structEncNC\\nc.latentEncNC = np.array([1, 2, 4, 8]) * 32\\nc.NLatent = np.array([0, 0, 0, 0]) * 16\\nc.DecInnerNC = np.array([1, 2, 4, 8]) * 32\\nc.DecNC = [\\n    c.structEncOutNC[i] + c.NLatent[i] + c.DecInnerNC[i] for i in range(c.depth - 1)\\n]\\nc.DecNC.append(c.structEncOutNC[c.depth - 1] + c.NLatent[c.depth - 1])\\n# c.VGGLayer = [4, 9, 16, 23]\\nc.VGGLayer = []\\nc.DiscDepth = 5\\nc.DiscNC = np.array([1, 2, 4, 8, 8]) * 32\\nc.device = \\\"cuda:0\\\"\\nc.batchSize = 8\\nc.lr = 0.001\\nc.epoch = 400\";\n",
       "                var nbb_formatted_code = \"class empty:\\n    pass\\n\\n\\nc = empty()\\nc.name = \\\"t0811\\\"\\nc.inputNC = 1\\nc.outputNC = 1\\nc.depth = 4\\nc.structEncNC = np.array([1, 2, 4, 8]) * 64\\nc.structEncOutNC = c.structEncNC\\nc.latentEncNC = np.array([1, 2, 4, 8]) * 32\\nc.NLatent = np.array([0, 0, 0, 0]) * 16\\nc.DecInnerNC = np.array([1, 2, 4, 8]) * 32\\nc.DecNC = [\\n    c.structEncOutNC[i] + c.NLatent[i] + c.DecInnerNC[i] for i in range(c.depth - 1)\\n]\\nc.DecNC.append(c.structEncOutNC[c.depth - 1] + c.NLatent[c.depth - 1])\\n# c.VGGLayer = [4, 9, 16, 23]\\nc.VGGLayer = []\\nc.DiscDepth = 5\\nc.DiscNC = np.array([1, 2, 4, 8, 8]) * 32\\nc.device = \\\"cuda:0\\\"\\nc.batchSize = 8\\nc.lr = 0.001\\nc.epoch = 400\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class empty:\n",
    "    pass\n",
    "\n",
    "\n",
    "c = empty()\n",
    "c.name = \"t0811\"\n",
    "c.inputNC = 1\n",
    "c.outputNC = 1\n",
    "c.depth = 4\n",
    "c.structEncNC = np.array([1, 2, 4, 8]) * 64\n",
    "c.structEncOutNC = c.structEncNC\n",
    "c.latentEncNC = np.array([1, 2, 4, 8]) * 32\n",
    "c.NLatent = np.array([0, 0, 0, 0]) * 16\n",
    "c.DecInnerNC = np.array([1, 2, 4, 8]) * 32\n",
    "c.DecNC = [\n",
    "    c.structEncOutNC[i] + c.NLatent[i] + c.DecInnerNC[i] for i in range(c.depth - 1)\n",
    "]\n",
    "c.DecNC.append(c.structEncOutNC[c.depth - 1] + c.NLatent[c.depth - 1])\n",
    "# c.VGGLayer = [4, 9, 16, 23]\n",
    "c.VGGLayer = []#=======================================\n",
    "c.DiscDepth = 5\n",
    "c.DiscNC = np.array([1, 2, 4, 8, 8]) * 32\n",
    "c.device = \"cuda:0\"\n",
    "c.batchSize = 8\n",
    "c.lr = 0.001\n",
    "c.epoch = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"dataset = torchvision.datasets.ImageFolder(\\n    \\\"/home/host/pytorch-CycleGAN-and-pix2pix/datasets/Taiwan_31to1/\\\"\\n)\\nwidth = dataset[0][0].width / 2\\ntoTensor = torchvision.transforms.ToTensor()\\ntrainset = [\\n    {\\n        \\\"X\\\": toTensor(img[0].crop((0, 0, width, width)))[0].unsqueeze(0),\\n        \\\"Y\\\": toTensor(img[0].crop((width, 0, width * 2, width)))[0].unsqueeze(0),\\n    }\\n    for img in dataset\\n    if img[1] == dataset.class_to_idx[\\\"train\\\"]\\n]\\nvalset = [\\n    {\\n        \\\"X\\\": toTensor(img[0].crop((0, 0, width, width)))[0].unsqueeze(0),\\n        \\\"Y\\\": toTensor(img[0].crop((width, 0, width * 2, width)))[0].unsqueeze(0),\\n    }\\n    for img in dataset\\n    if img[1] == dataset.class_to_idx[\\\"val\\\"]\\n]\\ntestset = [\\n    {\\n        \\\"X\\\": toTensor(img[0].crop((0, 0, width, width)))[0].unsqueeze(0),\\n        \\\"Y\\\": toTensor(img[0].crop((width, 0, width * 2, width)))[0].unsqueeze(0),\\n    }\\n    for img in dataset\\n    if img[1] == dataset.class_to_idx[\\\"test\\\"]\\n]\";\n",
       "                var nbb_formatted_code = \"dataset = torchvision.datasets.ImageFolder(\\n    \\\"/home/host/pytorch-CycleGAN-and-pix2pix/datasets/Taiwan_31to1/\\\"\\n)\\nwidth = dataset[0][0].width / 2\\ntoTensor = torchvision.transforms.ToTensor()\\ntrainset = [\\n    {\\n        \\\"X\\\": toTensor(img[0].crop((0, 0, width, width)))[0].unsqueeze(0),\\n        \\\"Y\\\": toTensor(img[0].crop((width, 0, width * 2, width)))[0].unsqueeze(0),\\n    }\\n    for img in dataset\\n    if img[1] == dataset.class_to_idx[\\\"train\\\"]\\n]\\nvalset = [\\n    {\\n        \\\"X\\\": toTensor(img[0].crop((0, 0, width, width)))[0].unsqueeze(0),\\n        \\\"Y\\\": toTensor(img[0].crop((width, 0, width * 2, width)))[0].unsqueeze(0),\\n    }\\n    for img in dataset\\n    if img[1] == dataset.class_to_idx[\\\"val\\\"]\\n]\\ntestset = [\\n    {\\n        \\\"X\\\": toTensor(img[0].crop((0, 0, width, width)))[0].unsqueeze(0),\\n        \\\"Y\\\": toTensor(img[0].crop((width, 0, width * 2, width)))[0].unsqueeze(0),\\n    }\\n    for img in dataset\\n    if img[1] == dataset.class_to_idx[\\\"test\\\"]\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = torchvision.datasets.ImageFolder(\n",
    "    \"/home/host/pytorch-CycleGAN-and-pix2pix/datasets/Taiwan_31to1/\"\n",
    ")\n",
    "width = dataset[0][0].width / 2\n",
    "toTensor = torchvision.transforms.ToTensor()\n",
    "trainset = [\n",
    "    {\n",
    "        \"X\": toTensor(img[0].crop((0, 0, width, width)))[0].unsqueeze(0),\n",
    "        \"Y\": toTensor(img[0].crop((width, 0, width * 2, width)))[0].unsqueeze(0),\n",
    "    }\n",
    "    for img in dataset\n",
    "    if img[1] == dataset.class_to_idx[\"train\"]\n",
    "]\n",
    "valset = [\n",
    "    {\n",
    "        \"X\": toTensor(img[0].crop((0, 0, width, width)))[0].unsqueeze(0),\n",
    "        \"Y\": toTensor(img[0].crop((width, 0, width * 2, width)))[0].unsqueeze(0),\n",
    "    }\n",
    "    for img in dataset\n",
    "    if img[1] == dataset.class_to_idx[\"val\"]\n",
    "]\n",
    "testset = [\n",
    "    {\n",
    "        \"X\": toTensor(img[0].crop((0, 0, width, width)))[0].unsqueeze(0),\n",
    "        \"Y\": toTensor(img[0].crop((width, 0, width * 2, width)))[0].unsqueeze(0),\n",
    "    }\n",
    "    for img in dataset\n",
    "    if img[1] == dataset.class_to_idx[\"test\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"import network\\n\\nt = torch.tensor\\nstructuralEncoder = network.Encoder(\\n    c.depth, c.inputNC, c.structEncNC, c.structEncOutNC\\n).to(c.device)\\nlatentEncoder = network.Encoder(\\n    c.depth, c.inputNC * 2, c.latentEncNC, [n * 2 for n in c.NLatent]\\n).to(c.device)\\ndecoder = network.Decoder(c.depth, c.DecInnerNC, c.DecNC, c.outputNC).to(c.device)\\ndiscriminator = network.Discriminator(c.DiscDepth, c.outputNC * 2, c.DiscNC).to(\\n    c.device\\n)\\n\\n\\ndef sampleLatent(param, c, stat=False):\\n    loss = torch.tensor(0.0, device=c.device)\\n    latent = []\\n    for i in range(c.depth):\\n        mean = param[i][:, : c.NLatent[i]]\\n        log_var = param[i][:, c.NLatent[i] :].mean(3).mean(2).unsqueeze(2).unsqueeze(3)\\n        var = torch.exp(log_var)\\n        epsilon = torch.normal(torch.zeros_like(mean), torch.ones_like(var))\\n        latent.append(mean + torch.sqrt(var) * epsilon)\\n        if param[i].nelement() != 0:\\n            loss += ((mean * mean).mean() + var.mean() - log_var.mean() - 1.0) / 2\\n    if stat:\\n        return latent, loss, (mean * mean).mean(1).sqrt().mean(), var.mean()\\n    else:\\n        return latent, loss\";\n",
       "                var nbb_formatted_code = \"import network\\n\\nt = torch.tensor\\nstructuralEncoder = network.Encoder(\\n    c.depth, c.inputNC, c.structEncNC, c.structEncOutNC\\n).to(c.device)\\nlatentEncoder = network.Encoder(\\n    c.depth, c.inputNC * 2, c.latentEncNC, [n * 2 for n in c.NLatent]\\n).to(c.device)\\ndecoder = network.Decoder(c.depth, c.DecInnerNC, c.DecNC, c.outputNC).to(c.device)\\ndiscriminator = network.Discriminator(c.DiscDepth, c.outputNC * 2, c.DiscNC).to(\\n    c.device\\n)\\n\\n\\ndef sampleLatent(param, c, stat=False):\\n    loss = torch.tensor(0.0, device=c.device)\\n    latent = []\\n    for i in range(c.depth):\\n        mean = param[i][:, : c.NLatent[i]]\\n        log_var = param[i][:, c.NLatent[i] :].mean(3).mean(2).unsqueeze(2).unsqueeze(3)\\n        var = torch.exp(log_var)\\n        epsilon = torch.normal(torch.zeros_like(mean), torch.ones_like(var))\\n        latent.append(mean + torch.sqrt(var) * epsilon)\\n        if param[i].nelement() != 0:\\n            loss += ((mean * mean).mean() + var.mean() - log_var.mean() - 1.0) / 2\\n    if stat:\\n        return latent, loss, (mean * mean).mean(1).sqrt().mean(), var.mean()\\n    else:\\n        return latent, loss\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import network\n",
    "\n",
    "t = torch.tensor\n",
    "structuralEncoder = network.Encoder(\n",
    "    c.depth, c.inputNC, c.structEncNC, c.structEncOutNC\n",
    ").to(c.device)\n",
    "latentEncoder = network.Encoder(\n",
    "    c.depth, c.inputNC * 2, c.latentEncNC, [n * 2 for n in c.NLatent]\n",
    ").to(c.device)\n",
    "decoder = network.Decoder(c.depth, c.DecInnerNC, c.DecNC, c.outputNC).to(c.device)\n",
    "discriminator = network.Discriminator(c.DiscDepth, c.outputNC * 2, c.DiscNC).to(\n",
    "    c.device\n",
    ")\n",
    "\n",
    "\n",
    "def sampleLatent(param, c, stat=False):\n",
    "    loss = torch.tensor(0.0, device=c.device)\n",
    "    latent = []\n",
    "    for i in range(c.depth):\n",
    "        mean = param[i][:, : c.NLatent[i]]\n",
    "        log_var = param[i][:, c.NLatent[i] :].mean(3).mean(2).unsqueeze(2).unsqueeze(3)\n",
    "        var = torch.exp(log_var)\n",
    "        epsilon = torch.normal(torch.zeros_like(mean), torch.ones_like(var))\n",
    "        latent.append(mean + torch.sqrt(var) * epsilon)\n",
    "        if param[i].nelement() != 0:\n",
    "            loss += ((mean * mean).mean() + var.mean() - log_var.mean() - 1.0) / 2\n",
    "    if stat:\n",
    "        return latent, loss, (mean * mean).mean(1).sqrt().mean(), var.mean()\n",
    "    else:\n",
    "        return latent, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"import os\\nfrom torchvision.utils import save_image\\ndef save(epoch,image=None):\\n    epoch = \\\"{:03}\\\".format(epoch)\\n    path = \\\"./checkpoints/\\\" + c.name + \\\"/\\\" + epoch + \\\"/\\\"\\n    if not (c.name in os.listdir(\\\"./checkpoints/\\\")):\\n        os.mkdir(\\\"./checkpoints/\\\" + c.name)\\n    if not (epoch in os.listdir(\\\"./checkpoints/\\\" + c.name)):\\n        os.mkdir(\\\"./checkpoints/\\\" + c.name + \\\"/\\\" + epoch)\\n    torch.save(structuralEncoder, path + \\\"str\\\")\\n    torch.save(latentEncoder, path + \\\"lat\\\")\\n    torch.save(decoder, path + \\\"dec\\\")\\n    torch.save(discriminator, path + \\\"dis\\\")\\n    torch.save(discriminator, path + \\\"dis\\\")\\n    if image !=None:\\n        save_image(image,path+\\\"sample.png\\\")\\n    with open(\\\"checkpoints/\\\" + c.name + \\\"/options.txt\\\", \\\"w+\\\") as fp:\\n        fp.write(str(c.__dict__))\\n\\ndef test(epoch):\\n    epoch = \\\"{:03}\\\".format(epoch)\\n    path = \\\"./checkpoints/\\\" + c.name + \\\"/\\\" + epoch + \\\"/\\\"\\n    structuralEncoder.eval()\\n    latentEncoder.eval()\\n    decoder.eval()\\n    discriminator.eval()\\n    test_result = util.test(c, valset, structuralEncoder, latentEncoder, decoder, crit_perceptual)\\n    sample = test_result[\\\"sample\\\"]\\n    del test_result[\\\"sample\\\"]\\n    with open(path + \\\"test_result.txt\\\", \\\"w+\\\") as fp:\\n        fp.write(str(test_result))\\n\\n    save_image(sample[0], path + \\\"test_sample.png\\\")\\n    structuralEncoder.train()\\n    latentEncoder.train()\\n    decoder.train()\\n    discriminator.train()\\n\\nos.system(\\\"visdom -port 80\\\")\\nimport visdom\\n\\nvis = visdom.Visdom(port=80, server=\\\"127.0.0.1\\\")\\nloader = torch.utils.data.DataLoader(trainset, batch_size=c.batchSize, shuffle=True)\\nL1 = torch.nn.L1Loss().to(c.device)\\ncrit_GAN = torch.nn.BCEWithLogitsLoss().to(c.device)\\ncrit_perceptual = network.VGGPerceptualLoss(c.VGGLayer).to(c.device)\\n# crit_GAN = torch.nn.MSELoss().to(c.device)\\nrealLabel = torch.tensor([[1.0]] * c.batchSize).to(c.device)\\nfakeLabel = torch.tensor([[0.0]] * c.batchSize).to(c.device)\\ndef req_grad(net, r):\\n    for param in net.parameters():\\n        param.requires_grad = r\";\n",
       "                var nbb_formatted_code = \"import os\\nfrom torchvision.utils import save_image\\n\\n\\ndef save(epoch, image=None):\\n    epoch = \\\"{:03}\\\".format(epoch)\\n    path = \\\"./checkpoints/\\\" + c.name + \\\"/\\\" + epoch + \\\"/\\\"\\n    if not (c.name in os.listdir(\\\"./checkpoints/\\\")):\\n        os.mkdir(\\\"./checkpoints/\\\" + c.name)\\n    if not (epoch in os.listdir(\\\"./checkpoints/\\\" + c.name)):\\n        os.mkdir(\\\"./checkpoints/\\\" + c.name + \\\"/\\\" + epoch)\\n    torch.save(structuralEncoder, path + \\\"str\\\")\\n    torch.save(latentEncoder, path + \\\"lat\\\")\\n    torch.save(decoder, path + \\\"dec\\\")\\n    torch.save(discriminator, path + \\\"dis\\\")\\n    torch.save(discriminator, path + \\\"dis\\\")\\n    if image != None:\\n        save_image(image, path + \\\"sample.png\\\")\\n    with open(\\\"checkpoints/\\\" + c.name + \\\"/options.txt\\\", \\\"w+\\\") as fp:\\n        fp.write(str(c.__dict__))\\n\\n\\ndef test(epoch):\\n    epoch = \\\"{:03}\\\".format(epoch)\\n    path = \\\"./checkpoints/\\\" + c.name + \\\"/\\\" + epoch + \\\"/\\\"\\n    structuralEncoder.eval()\\n    latentEncoder.eval()\\n    decoder.eval()\\n    discriminator.eval()\\n    test_result = util.test(\\n        c, valset, structuralEncoder, latentEncoder, decoder, crit_perceptual\\n    )\\n    sample = test_result[\\\"sample\\\"]\\n    del test_result[\\\"sample\\\"]\\n    with open(path + \\\"test_result.txt\\\", \\\"w+\\\") as fp:\\n        fp.write(str(test_result))\\n\\n    save_image(sample[0], path + \\\"test_sample.png\\\")\\n    structuralEncoder.train()\\n    latentEncoder.train()\\n    decoder.train()\\n    discriminator.train()\\n\\n\\nos.system(\\\"visdom -port 80\\\")\\nimport visdom\\n\\nvis = visdom.Visdom(port=80, server=\\\"127.0.0.1\\\")\\nloader = torch.utils.data.DataLoader(trainset, batch_size=c.batchSize, shuffle=True)\\nL1 = torch.nn.L1Loss().to(c.device)\\ncrit_GAN = torch.nn.BCEWithLogitsLoss().to(c.device)\\ncrit_perceptual = network.VGGPerceptualLoss(c.VGGLayer).to(c.device)\\n# crit_GAN = torch.nn.MSELoss().to(c.device)\\nrealLabel = torch.tensor([[1.0]] * c.batchSize).to(c.device)\\nfakeLabel = torch.tensor([[0.0]] * c.batchSize).to(c.device)\\n\\n\\ndef req_grad(net, r):\\n    for param in net.parameters():\\n        param.requires_grad = r\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from torchvision.utils import save_image\n",
    "def save(epoch,image=None):\n",
    "    epoch = \"{:03}\".format(epoch)\n",
    "    path = \"./checkpoints/\" + c.name + \"/\" + epoch + \"/\"\n",
    "    if not (c.name in os.listdir(\"./checkpoints/\")):\n",
    "        os.mkdir(\"./checkpoints/\" + c.name)\n",
    "    if not (epoch in os.listdir(\"./checkpoints/\" + c.name)):\n",
    "        os.mkdir(\"./checkpoints/\" + c.name + \"/\" + epoch)\n",
    "    torch.save(structuralEncoder, path + \"str\")\n",
    "    torch.save(latentEncoder, path + \"lat\")\n",
    "    torch.save(decoder, path + \"dec\")\n",
    "    torch.save(discriminator, path + \"dis\")\n",
    "    torch.save(discriminator, path + \"dis\")\n",
    "    if image !=None:\n",
    "        save_image(image,path+\"sample.png\")\n",
    "    with open(\"checkpoints/\" + c.name + \"/options.txt\", \"w+\") as fp:\n",
    "        fp.write(str(c.__dict__))\n",
    "\n",
    "def test(epoch):\n",
    "    epoch = \"{:03}\".format(epoch)\n",
    "    path = \"./checkpoints/\" + c.name + \"/\" + epoch + \"/\"\n",
    "    structuralEncoder.eval()\n",
    "    latentEncoder.eval()\n",
    "    decoder.eval()\n",
    "    discriminator.eval()\n",
    "    test_result = util.test(c, valset, structuralEncoder, latentEncoder, decoder, crit_perceptual)\n",
    "    sample = test_result[\"sample\"]\n",
    "    del test_result[\"sample\"]\n",
    "    with open(path + \"test_result.txt\", \"w+\") as fp:\n",
    "        fp.write(str(test_result))\n",
    "\n",
    "    save_image(sample[0], path + \"test_sample.png\")\n",
    "    structuralEncoder.train()\n",
    "    latentEncoder.train()\n",
    "    decoder.train()\n",
    "    discriminator.train()\n",
    "\n",
    "os.system(\"visdom -port 80\")\n",
    "import visdom\n",
    "\n",
    "vis = visdom.Visdom(port=80, server=\"127.0.0.1\")\n",
    "loader = torch.utils.data.DataLoader(trainset, batch_size=c.batchSize, shuffle=True)\n",
    "L1 = torch.nn.L1Loss().to(c.device)\n",
    "crit_GAN = torch.nn.BCEWithLogitsLoss().to(c.device)\n",
    "crit_perceptual = network.VGGPerceptualLoss(c.VGGLayer).to(c.device)\n",
    "# crit_GAN = torch.nn.MSELoss().to(c.device)\n",
    "realLabel = torch.tensor([[1.0]] * c.batchSize).to(c.device)\n",
    "fakeLabel = torch.tensor([[0.0]] * c.batchSize).to(c.device)\n",
    "def req_grad(net, r):\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"lossRec = []\\nepochCount = []\\ntotal_epoch = 0\";\n",
       "                var nbb_formatted_code = \"lossRec = []\\nepochCount = []\\ntotal_epoch = 0\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lossRec = []\n",
    "epochCount = []\n",
    "total_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"optimG = torch.optim.Adam(\\n    lr=c.lr,\\n    params=list(structuralEncoder.parameters())\\n    + list(latentEncoder.parameters())\\n    + list(decoder.parameters()),\\n)\\noptimD = torch.optim.Adam(lr=c.lr, params=discriminator.parameters())\\nschedulerG = torch.optim.lr_scheduler.LambdaLR(\\n    optimG, lambda x: max(min(1, 2 - 2 * x / c.epoch), 0)\\n)\\nschedulerD = torch.optim.lr_scheduler.LambdaLR(\\n    optimD, lambda x: max(min(1, 2 - 2 * x / c.epoch), 0)\\n)\\nlatentLossWeight = c.latentLossWeight = 0.00\\nL1LossWeight = c.L1LossWeight = 0\\nGANLossGWeight = c.GANLossGWeight = 1\\nGANLossDWeight = c.GANLossDWeight = 1\\nperceptualLossWeight = c.PerceptualLossWeight = 0\";\n",
       "                var nbb_formatted_code = \"optimG = torch.optim.Adam(\\n    lr=c.lr,\\n    params=list(structuralEncoder.parameters())\\n    + list(latentEncoder.parameters())\\n    + list(decoder.parameters()),\\n)\\noptimD = torch.optim.Adam(lr=c.lr, params=discriminator.parameters())\\nschedulerG = torch.optim.lr_scheduler.LambdaLR(\\n    optimG, lambda x: max(min(1, 2 - 2 * x / c.epoch), 0)\\n)\\nschedulerD = torch.optim.lr_scheduler.LambdaLR(\\n    optimD, lambda x: max(min(1, 2 - 2 * x / c.epoch), 0)\\n)\\nlatentLossWeight = c.latentLossWeight = 0.00\\nL1LossWeight = c.L1LossWeight = 0\\nGANLossGWeight = c.GANLossGWeight = 1\\nGANLossDWeight = c.GANLossDWeight = 1\\nperceptualLossWeight = c.PerceptualLossWeight = 0\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimG = torch.optim.Adam(\n",
    "    lr=c.lr,\n",
    "    params=list(structuralEncoder.parameters())\n",
    "    + list(latentEncoder.parameters())\n",
    "    + list(decoder.parameters()),\n",
    ")\n",
    "optimD = torch.optim.Adam(lr=c.lr, params=discriminator.parameters())\n",
    "schedulerG = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimG, lambda x: max(min(1, 2 - 2 * x / c.epoch), 0)\n",
    ")\n",
    "schedulerD = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimD, lambda x: max(min(1, 2 - 2 * x / c.epoch), 0)\n",
    ")\n",
    "latentLossWeight = c.latentLossWeight = 0.00\n",
    "L1LossWeight = c.L1LossWeight = 0\n",
    "GANLossGWeight = c.GANLossGWeight = 1\n",
    "GANLossDWeight = c.GANLossDWeight = 1\n",
    "perceptualLossWeight = c.PerceptualLossWeight = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 5/400 [02:54<3:49:28, 34.86s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-70f7876b36d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mepoch_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtot_iter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             vis.images(\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mwin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scifair/lib/python3.8/site-packages/visdom/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scifair/lib/python3.8/site-packages/visdom/__init__.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scifair/lib/python3.8/site-packages/visdom/__init__.py\u001b[0m in \u001b[0;36m_to_numpy\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'detach'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"from tqdm import tqdm\\n\\n\\nstructuralEncoder.train()\\nlatentEncoder.train()\\ndecoder.train()\\ndiscriminator.train()\\n\\ntot_iter = 0\\nfor epoch in tqdm(range(c.epoch)):\\n    if total_epoch >= c.epoch:\\n        break\\n    epoch_iter = 0\\n    for i, data in enumerate(loader):\\n        X = data[\\\"X\\\"].to(c.device)\\n        Y = data[\\\"Y\\\"].to(c.device)\\n        # Y = trainset[0][\\\"Y\\\"].repeat(8,1,1,1).to(c.device)\\n\\n        structure = structuralEncoder(X)\\n        latent, latentLoss = sampleLatent(latentEncoder(torch.cat([X, Y], dim=1)), c)\\n        latentLoss *= latentLossWeight\\n\\n        Y_pred = decoder(structure, latent) + X\\n        L1Loss = L1(Y_pred, Y) * L1LossWeight\\n\\n        # dOut = discriminator(torch.cat([X, Y_pred], dim=1))#==================\\n        dOut = discriminator(torch.cat([Y, Y_pred], dim=1))\\n        GANLossG = crit_GAN(dOut, realLabel) * GANLossGWeight\\n\\n        VGGLoss = crit_perceptual(Y, Y_pred) * perceptualLossWeight\\n\\n        req_grad(discriminator, False)\\n        optimG.zero_grad()\\n        (latentLoss + L1Loss + GANLossG + VGGLoss).backward()\\n        optimG.step()\\n        req_grad(discriminator, True)\\n        # dOut = discriminator(torch.cat([X, Y_pred], dim=1).detach())#======================\\n        dOut = discriminator(torch.cat([Y, Y_pred], dim=1).detach())\\n        GANLossD = crit_GAN(dOut, fakeLabel) * GANLossDWeight\\n        # dOut = discriminator(torch.cat([X, Y], dim=1))#======================\\n        dOut = discriminator(torch.cat([Y, Y], dim=1))\\n        GANLossD += crit_GAN(dOut, realLabel) * GANLossDWeight\\n\\n        optimD.zero_grad()\\n        GANLossD.backward()\\n        optimD.step()\\n\\n        tot_iter += 1\\n        epoch_iter += 1\\n        if tot_iter % 20 == 0:\\n            vis.images(\\n                torch.clamp(torch.stack([X[0], Y_pred[0], Y[0]], dim=0) * 256, 0, 256),\\n                win=\\\"img\\\",\\n            )\\n            \\\"\\\"\\\"test validation set\\\"\\\"\\\"\\n            X_val = []\\n            Y_val = []\\n            idx = random.sample(range(len(valset)), c.batchSize)\\n            for i in idx:\\n                sample = valset[i]\\n                X_val.append(sample[\\\"X\\\"])\\n                Y_val.append(sample[\\\"Y\\\"])\\n            X_val = torch.stack(X_val, dim=0).to(c.device)\\n            Y_val = torch.stack(Y_val, dim=0).to(c.device)\\n            structure = structuralEncoder(X_val)\\n            latent, val_latentLoss, RMS_miu, mean_var = util.sampleLatent(\\n                latentEncoder(torch.cat([X_val, Y_val], dim=1)), c, True\\n            )\\n            val_latentLoss *= latentLossWeight\\n\\n            Y_pred_val = decoder(structure, latent) + X_val\\n            val_L1Loss = L1(Y_pred_val, Y_val) * L1LossWeight\\n            val_VGGLoss = crit_perceptual(Y_pred_val, Y_val) * perceptualLossWeight\\n            vis.images(\\n                torch.clamp(\\n                    torch.stack([X_val[0], Y_pred_val[0], Y_val[0]], dim=0) * 256,\\n                    0,\\n                    256,\\n                ),\\n                win=\\\"img_val\\\",\\n            )\\n            lossRec.append(\\n                [\\n                    latentLoss.item(),\\n                    L1Loss.item(),\\n                    VGGLoss.item(),\\n                    GANLossG.item(),\\n                    GANLossD.item(),\\n                    val_latentLoss.item(),\\n                    # val_L1Loss.item(),\\n                    L1(\\n                        Y_pred_val, Y_val\\n                    ).item(),  # ==============================================\\n                    val_VGGLoss.item(),\\n                    RMS_miu[3],\\n                    mean_var[3],\\n                ]\\n            )\\n            epochCount.append(\\n                [total_epoch + epoch_iter * c.batchSize / len(trainset)] * 10\\n            )\\n            vis.line(\\n                lossRec,\\n                epochCount,\\n                opts={\\n                    \\\"title\\\": c.name + \\\" loss over time\\\",\\n                    \\\"legend\\\": \\\"latentLoss,L1Loss,VGG,GAN_G,GAN_D,val_latentLoss,val_L1Loss,val_VGGLoss,val_RMS_miu,val_mean_var\\\".split(\\n                        \\\",\\\"\\n                    ),\\n                    \\\"xlabel\\\": \\\"epoch\\\",\\n                    \\\"ylabel\\\": \\\"loss\\\",\\n                },\\n                win=\\\"loss\\\",\\n            )\\n    total_epoch += 1\\n    if total_epoch % 20 == 0:\\n        save(\\n            total_epoch,\\n            torch.cat(\\n                [\\n                    torch.cat((X, Y_pred, Y), dim=3)[0],\\n                    torch.cat((X_val, Y_pred_val, Y_val), dim=3)[0],\\n                ],\\n                dim=1,\\n            ),\\n        )\\n    schedulerG.step()\\n    schedulerD.step()\\nsave(total_epoch)\";\n",
       "                var nbb_formatted_code = \"from tqdm import tqdm\\n\\n\\nstructuralEncoder.train()\\nlatentEncoder.train()\\ndecoder.train()\\ndiscriminator.train()\\n\\ntot_iter = 0\\nfor epoch in tqdm(range(c.epoch)):\\n    if total_epoch >= c.epoch:\\n        break\\n    epoch_iter = 0\\n    for i, data in enumerate(loader):\\n        X = data[\\\"X\\\"].to(c.device)\\n        Y = data[\\\"Y\\\"].to(c.device)\\n        # Y = trainset[0][\\\"Y\\\"].repeat(8,1,1,1).to(c.device)\\n\\n        structure = structuralEncoder(X)\\n        latent, latentLoss = sampleLatent(latentEncoder(torch.cat([X, Y], dim=1)), c)\\n        latentLoss *= latentLossWeight\\n\\n        Y_pred = decoder(structure, latent) + X\\n        L1Loss = L1(Y_pred, Y) * L1LossWeight\\n\\n        # dOut = discriminator(torch.cat([X, Y_pred], dim=1))#==================\\n        dOut = discriminator(torch.cat([Y, Y_pred], dim=1))\\n        GANLossG = crit_GAN(dOut, realLabel) * GANLossGWeight\\n\\n        VGGLoss = crit_perceptual(Y, Y_pred) * perceptualLossWeight\\n\\n        req_grad(discriminator, False)\\n        optimG.zero_grad()\\n        (latentLoss + L1Loss + GANLossG + VGGLoss).backward()\\n        optimG.step()\\n        req_grad(discriminator, True)\\n        # dOut = discriminator(torch.cat([X, Y_pred], dim=1).detach())#======================\\n        dOut = discriminator(torch.cat([Y, Y_pred], dim=1).detach())\\n        GANLossD = crit_GAN(dOut, fakeLabel) * GANLossDWeight\\n        # dOut = discriminator(torch.cat([X, Y], dim=1))#======================\\n        dOut = discriminator(torch.cat([Y, Y], dim=1))\\n        GANLossD += crit_GAN(dOut, realLabel) * GANLossDWeight\\n\\n        optimD.zero_grad()\\n        GANLossD.backward()\\n        optimD.step()\\n\\n        tot_iter += 1\\n        epoch_iter += 1\\n        if tot_iter % 20 == 0:\\n            vis.images(\\n                torch.clamp(torch.stack([X[0], Y_pred[0], Y[0]], dim=0) * 256, 0, 256),\\n                win=\\\"img\\\",\\n            )\\n            \\\"\\\"\\\"test validation set\\\"\\\"\\\"\\n            X_val = []\\n            Y_val = []\\n            idx = random.sample(range(len(valset)), c.batchSize)\\n            for i in idx:\\n                sample = valset[i]\\n                X_val.append(sample[\\\"X\\\"])\\n                Y_val.append(sample[\\\"Y\\\"])\\n            X_val = torch.stack(X_val, dim=0).to(c.device)\\n            Y_val = torch.stack(Y_val, dim=0).to(c.device)\\n            structure = structuralEncoder(X_val)\\n            latent, val_latentLoss, RMS_miu, mean_var = util.sampleLatent(\\n                latentEncoder(torch.cat([X_val, Y_val], dim=1)), c, True\\n            )\\n            val_latentLoss *= latentLossWeight\\n\\n            Y_pred_val = decoder(structure, latent) + X_val\\n            val_L1Loss = L1(Y_pred_val, Y_val) * L1LossWeight\\n            val_VGGLoss = crit_perceptual(Y_pred_val, Y_val) * perceptualLossWeight\\n            vis.images(\\n                torch.clamp(\\n                    torch.stack([X_val[0], Y_pred_val[0], Y_val[0]], dim=0) * 256,\\n                    0,\\n                    256,\\n                ),\\n                win=\\\"img_val\\\",\\n            )\\n            lossRec.append(\\n                [\\n                    latentLoss.item(),\\n                    L1Loss.item(),\\n                    VGGLoss.item(),\\n                    GANLossG.item(),\\n                    GANLossD.item(),\\n                    val_latentLoss.item(),\\n                    # val_L1Loss.item(),\\n                    L1(\\n                        Y_pred_val, Y_val\\n                    ).item(),  # ==============================================\\n                    val_VGGLoss.item(),\\n                    RMS_miu[3],\\n                    mean_var[3],\\n                ]\\n            )\\n            epochCount.append(\\n                [total_epoch + epoch_iter * c.batchSize / len(trainset)] * 10\\n            )\\n            vis.line(\\n                lossRec,\\n                epochCount,\\n                opts={\\n                    \\\"title\\\": c.name + \\\" loss over time\\\",\\n                    \\\"legend\\\": \\\"latentLoss,L1Loss,VGG,GAN_G,GAN_D,val_latentLoss,val_L1Loss,val_VGGLoss,val_RMS_miu,val_mean_var\\\".split(\\n                        \\\",\\\"\\n                    ),\\n                    \\\"xlabel\\\": \\\"epoch\\\",\\n                    \\\"ylabel\\\": \\\"loss\\\",\\n                },\\n                win=\\\"loss\\\",\\n            )\\n    total_epoch += 1\\n    if total_epoch % 20 == 0:\\n        save(\\n            total_epoch,\\n            torch.cat(\\n                [\\n                    torch.cat((X, Y_pred, Y), dim=3)[0],\\n                    torch.cat((X_val, Y_pred_val, Y_val), dim=3)[0],\\n                ],\\n                dim=1,\\n            ),\\n        )\\n    schedulerG.step()\\n    schedulerD.step()\\nsave(total_epoch)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "structuralEncoder.train()\n",
    "latentEncoder.train()\n",
    "decoder.train()\n",
    "discriminator.train()\n",
    "\n",
    "tot_iter = 0\n",
    "for epoch in tqdm(range(c.epoch)):\n",
    "    if total_epoch >= c.epoch:\n",
    "        break\n",
    "    epoch_iter = 0\n",
    "    for i, data in enumerate(loader):\n",
    "        X = data[\"X\"].to(c.device)\n",
    "        Y = data[\"Y\"].to(c.device)\n",
    "        # Y = trainset[0][\"Y\"].repeat(8,1,1,1).to(c.device)\n",
    "\n",
    "        structure = structuralEncoder(X)\n",
    "        latent, latentLoss = sampleLatent(latentEncoder(torch.cat([X, Y], dim=1)), c)\n",
    "        latentLoss *= latentLossWeight\n",
    "\n",
    "        Y_pred = decoder(structure, latent) + X\n",
    "        L1Loss = L1(Y_pred, Y) * L1LossWeight\n",
    "\n",
    "        # dOut = discriminator(torch.cat([X, Y_pred], dim=1))#==================\n",
    "        dOut = discriminator(torch.cat([Y, Y_pred], dim=1))\n",
    "        GANLossG = crit_GAN(dOut, realLabel) * GANLossGWeight\n",
    "\n",
    "        VGGLoss = crit_perceptual(Y, Y_pred) * perceptualLossWeight\n",
    "\n",
    "        req_grad(discriminator, False)\n",
    "        optimG.zero_grad()\n",
    "        (latentLoss + L1Loss + GANLossG + VGGLoss).backward()\n",
    "        optimG.step()\n",
    "        req_grad(discriminator, True)\n",
    "        # dOut = discriminator(torch.cat([X, Y_pred], dim=1).detach())#======================\n",
    "        dOut = discriminator(torch.cat([Y, Y_pred], dim=1).detach())\n",
    "        GANLossD = crit_GAN(dOut, fakeLabel) * GANLossDWeight\n",
    "        # dOut = discriminator(torch.cat([X, Y], dim=1))#======================\n",
    "        dOut = discriminator(torch.cat([Y, Y], dim=1))\n",
    "        GANLossD += crit_GAN(dOut, realLabel) * GANLossDWeight\n",
    "\n",
    "        optimD.zero_grad()\n",
    "        GANLossD.backward()\n",
    "        optimD.step()\n",
    "\n",
    "        tot_iter += 1\n",
    "        epoch_iter += 1\n",
    "        if tot_iter % 20 == 0:\n",
    "            vis.images(\n",
    "                torch.clamp(torch.stack([X[0], Y_pred[0], Y[0]], dim=0) * 256, 0, 256),\n",
    "                win=\"img\",\n",
    "            )\n",
    "            \"\"\"test validation set\"\"\"\n",
    "            X_val = []\n",
    "            Y_val = []\n",
    "            idx = random.sample(range(len(valset)), c.batchSize)\n",
    "            for i in idx:\n",
    "                sample = valset[i]\n",
    "                X_val.append(sample[\"X\"])\n",
    "                Y_val.append(sample[\"Y\"])\n",
    "            X_val = torch.stack(X_val, dim=0).to(c.device)\n",
    "            Y_val = torch.stack(Y_val, dim=0).to(c.device)\n",
    "            structure = structuralEncoder(X_val)\n",
    "            latent, val_latentLoss, RMS_miu, mean_var = util.sampleLatent(\n",
    "                latentEncoder(torch.cat([X_val, Y_val], dim=1)), c, True\n",
    "            )\n",
    "            val_latentLoss *= latentLossWeight\n",
    "\n",
    "            Y_pred_val = decoder(structure, latent) + X_val\n",
    "            val_L1Loss = L1(Y_pred_val, Y_val) * L1LossWeight\n",
    "            val_VGGLoss = crit_perceptual(Y_pred_val, Y_val) * perceptualLossWeight\n",
    "            vis.images(\n",
    "                torch.clamp(\n",
    "                    torch.stack([X_val[0], Y_pred_val[0], Y_val[0]], dim=0) * 256,\n",
    "                    0,\n",
    "                    256,\n",
    "                ),\n",
    "                win=\"img_val\",\n",
    "            )\n",
    "            lossRec.append(\n",
    "                [\n",
    "                    latentLoss.item(),\n",
    "                    L1Loss.item(),\n",
    "                    VGGLoss.item(),\n",
    "                    GANLossG.item(),\n",
    "                    GANLossD.item(),\n",
    "                    val_latentLoss.item(),\n",
    "                    # val_L1Loss.item(),\n",
    "                    L1(\n",
    "                        Y_pred_val, Y_val\n",
    "                    ).item(),  # ==============================================\n",
    "                    val_VGGLoss.item(),\n",
    "                    RMS_miu[3],\n",
    "                    mean_var[3],\n",
    "                ]\n",
    "            )\n",
    "            epochCount.append(\n",
    "                [total_epoch + epoch_iter * c.batchSize / len(trainset)] * 10\n",
    "            )\n",
    "            vis.line(\n",
    "                lossRec,\n",
    "                epochCount,\n",
    "                opts={\n",
    "                    \"title\": c.name + \" loss over time\",\n",
    "                    \"legend\": \"latentLoss,L1Loss,VGG,GAN_G,GAN_D,val_latentLoss,val_L1Loss,val_VGGLoss,val_RMS_miu,val_mean_var\".split(\n",
    "                        \",\"\n",
    "                    ),\n",
    "                    \"xlabel\": \"epoch\",\n",
    "                    \"ylabel\": \"loss\",\n",
    "                },\n",
    "                win=\"loss\",\n",
    "            )\n",
    "    total_epoch += 1\n",
    "    if total_epoch % 20 == 0:\n",
    "        save(\n",
    "            total_epoch,\n",
    "            torch.cat(\n",
    "                [\n",
    "                    torch.cat((X, Y_pred, Y), dim=3)[0],\n",
    "                    torch.cat((X_val, Y_pred_val, Y_val), dim=3)[0],\n",
    "                ],\n",
    "                dim=1,\n",
    "            ),\n",
    "        )\n",
    "    schedulerG.step()\n",
    "    schedulerD.step()\n",
    "save(total_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(total_epoch, torch.cat((X, Y_pred, Y), dim=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"torch.cuda.empty_cache()        \";\n",
       "                var nbb_formatted_code = \"torch.cuda.empty_cache()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"VGGLoss\";\n",
       "                var nbb_formatted_code = \"VGGLoss\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del structuralEncoder\n",
    "del latentEncoder\n",
    "del decoder\n",
    "del discriminator\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"del structuralEncoder\\ndel latentEncoder\\ndel decoder\\ndel discriminator\\nepoch_ = \\\"400\\\"\\npath = \\\"./checkpoints/\\\" + c.name + \\\"/\\\" + epoch_\\nstructuralEncoder = torch.load(path + \\\"/str\\\")\\nlatentEncoder = torch.load(path + \\\"/lat\\\")\\ndecoder = torch.load(path + \\\"/dec\\\")\\ndiscriminator = torch.load(path + \\\"/dis\\\")\";\n",
       "                var nbb_formatted_code = \"del structuralEncoder\\ndel latentEncoder\\ndel decoder\\ndel discriminator\\nepoch_ = \\\"400\\\"\\npath = \\\"./checkpoints/\\\" + c.name + \\\"/\\\" + epoch_\\nstructuralEncoder = torch.load(path + \\\"/str\\\")\\nlatentEncoder = torch.load(path + \\\"/lat\\\")\\ndecoder = torch.load(path + \\\"/dec\\\")\\ndiscriminator = torch.load(path + \\\"/dis\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "del structuralEncoder\n",
    "del latentEncoder\n",
    "del decoder\n",
    "del discriminator\n",
    "epoch_ = \"400\"\n",
    "path = \"./checkpoints/\" + c.name + \"/\" + epoch_\n",
    "structuralEncoder = torch.load(path + \"/str\")\n",
    "latentEncoder = torch.load(path + \"/lat\")\n",
    "decoder = torch.load(path + \"/dec\")\n",
    "discriminator = torch.load(path + \"/dis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structuralEncoder.train()\n",
    "latentEncoder.train()\n",
    "decoder.train()\n",
    "discriminator.train()\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "idx = random.sample(range(len(trainset)), c.batchSize)\n",
    "for i in idx:\n",
    "    sample = trainset[i]\n",
    "    X.append(sample[\"X\"])\n",
    "    Y.append(sample[\"Y\"])\n",
    "X = torch.stack(X, dim=0).to(c.device)\n",
    "Y = torch.stack(Y, dim=0).to(c.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = structuralEncoder(X)\n",
    "leout = latentEncoder(torch.cat([X, Y], dim=1))\n",
    "latent, latentLoss = sampleLatent(latentEncoder(torch.cat([X, Y], dim=1)), c)\n",
    "Y_pred = decoder(structure, latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"test(400)\";\n",
       "                var nbb_formatted_code = \"test(400)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.p(Y[6][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p(trainset[0][\"X\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util' from '/home/host/Autoencoder/util.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"util.reload(util)\";\n",
       "                var nbb_formatted_code = \"util.reload(util)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "util.reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del latentEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 80\n",
    "x = testset[0][\"X\"][0]\n",
    "x -= x.mean()\n",
    "f = torch.fft(torch.stack([x, torch.zeros_like(x)], dim=2), 2)\n",
    "f = (f[:, :, 0].pow(2) + f[:, :, 1].pow(2)).sqrt()\n",
    "util.p(util.fftshift(f)[b:-b, b:-b])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 100\n",
    "x = testset[0][\"Y\"][0]\n",
    "x -= x.mean()\n",
    "f = torch.fft(torch.stack([x, torch.zeros_like(x)], dim=2), 2)\n",
    "f = (f[:, :, 0].pow(2) + f[:, :, 1].pow(2)).sqrt()\n",
    "util.p(util.fftshift(f)[b:-b, b:-b])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.p(x)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"f=lambda x: max(min(1, 2 - 2 * x / c.epoch), 0)\";\n",
       "                var nbb_formatted_code = \"f = lambda x: max(min(1, 2 - 2 * x / c.epoch), 0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = lambda x: max(min(1, 2 - 2 * x / c.epoch), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"f(4000)\";\n",
       "                var nbb_formatted_code = \"f(4000)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
